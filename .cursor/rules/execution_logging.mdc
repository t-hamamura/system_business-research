# å®Ÿè¡Œãƒ­ã‚°æ©Ÿèƒ½ãƒ«ãƒ¼ãƒ«ï¼ˆv2.0: çµ±è¨ˆãƒ»ç›£æŸ»å¯¾å¿œï¼‰

## æ¦‚è¦
ã™ã¹ã¦ã®èª¿æŸ»å®Ÿè¡Œæ™‚ã«è©³ç´°ãªãƒ­ã‚°ã‚’è¨˜éŒ²ã—ã€å®Ÿè¡Œçµ±è¨ˆã€ä½¿ç”¨ãƒªã‚½ãƒ¼ã‚¹ã€ã‚¨ãƒ©ãƒ¼æƒ…å ±ã‚’ç®¡ç†ã™ã‚‹ã€‚

## å®Ÿè¡Œãƒ­ã‚°æ©Ÿèƒ½
```python
import json
import os
from datetime import datetime
import traceback
import hashlib

def init_execution_log(research_type, target, model="claude"):
    """
    å®Ÿè¡Œé–‹å§‹æ™‚ã®ãƒ­ã‚°åˆæœŸåŒ–
    """
    return {
        "execution_id": datetime.now().strftime("%Y%m%d_%H%M%S"),
        "research_type": research_type,
        "target": target,
        "model": model,
        "start_time": datetime.now().isoformat(),
        "duration": 0,
        "status": "running",
        "search_count": 0,
        "tokens": 0,
        "cost": 0,
        "sources": 0,
        "files": [],
        "credibility": {"A": 0, "B": 0, "C": 0},
        "quality_score": 0,
        "errors": [],
        "warnings": []
    }

def log_search_call(log_data, query, results_count=0, tokens_used=0):
    """
    æ¤œç´¢å®Ÿè¡Œãƒ­ã‚°
    """
    log_data["search_count"] += 1
    log_data["tokens"] += tokens_used
    log_data["sources"] += results_count
    
    # ã‚³ã‚¹ãƒˆæ¦‚ç®—ï¼ˆClaudeåŸºæº–ï¼‰
    cost_per_token = 0.0075 / 1000  # å††/ãƒˆãƒ¼ã‚¯ãƒ³
    log_data["cost"] = log_data["tokens"] * cost_per_token
    
    return log_data

def log_credibility_source(log_data, tier):
    """
    ä¿¡é ¼åº¦åˆ¥ã‚½ãƒ¼ã‚¹æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
    """
    if tier in ["A", "B", "C"]:
        log_data["credibility"][tier] += 1
    return log_data

def log_error(log_data, error_message, error_type="general"):
    """
    ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°è¨˜éŒ²
    """
    error_entry = {
        "timestamp": datetime.now().isoformat(),
        "type": error_type,
        "message": str(error_message),
        "traceback": traceback.format_exc() if error_type == "exception" else None
    }
    log_data["errors"].append(error_entry)
    log_data["status"] = "error"
    return log_data

def log_warning(log_data, warning_message, warning_type="general"):
    """
    è­¦å‘Šãƒ­ã‚°è¨˜éŒ²
    """
    warning_entry = {
        "timestamp": datetime.now().isoformat(),
        "type": warning_type,
        "message": str(warning_message)
    }
    log_data["warnings"].append(warning_entry)
    return log_data

def log_output_file(log_data, file_path, file_type="markdown"):
    """
    å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ­ã‚°
    """
    file_info = {
        "path": file_path,
        "type": file_type,
        "size": os.path.getsize(file_path) if os.path.exists(file_path) else 0,
        "created_at": datetime.now().isoformat()
    }
    log_data["files"].append(file_info)
    return log_data

def calculate_quality_score(log_data, content_length=0):
    """
    å“è³ªã‚¹ã‚³ã‚¢è¨ˆç®—
    """
    score = 100
    
    # ã‚½ãƒ¼ã‚¹æ•°ãƒã‚§ãƒƒã‚¯ï¼ˆæœ€ä½5ä»¶ï¼‰
    if log_data["sources"] < 5:
        score -= (5 - log_data["sources"]) * 10
    
    # ä¿¡é ¼åº¦åˆ†å¸ƒãƒã‚§ãƒƒã‚¯
    total_sources = sum(log_data["credibility"].values())
    if total_sources > 0:
        a_ratio = log_data["credibility"]["A"] / total_sources
        if a_ratio < 0.3:  # Aç´šã‚½ãƒ¼ã‚¹ãŒ30%æœªæº€
            score -= 15
    
    # ã‚³ãƒ³ãƒ†ãƒ³ãƒ„é•·ãƒã‚§ãƒƒã‚¯
    if content_length < 2000:
        score -= 20
    
    # ã‚¨ãƒ©ãƒ¼ãƒ»è­¦å‘ŠãƒšãƒŠãƒ«ãƒ†ã‚£
    score -= len(log_data["errors"]) * 15
    score -= len(log_data["warnings"]) * 5
    
    log_data["quality_score"] = max(0, score)
    return log_data

def finish_execution_log(log_data, content_length=0):
    """
    å®Ÿè¡Œå®Œäº†æ™‚ã®ãƒ­ã‚°ç¢ºå®š
    """
    end_time = datetime.now()
    start_time = datetime.fromisoformat(log_data["start_time"])
    log_data["duration"] = int((end_time - start_time).total_seconds())
    
    if log_data["status"] == "running":
        log_data["status"] = "completed"
    
    # å“è³ªã‚¹ã‚³ã‚¢è¨ˆç®—
    log_data = calculate_quality_score(log_data, content_length)
    
    return log_data

def save_execution_log(folder_path, log_data):
    """
    å®Ÿè¡Œãƒ­ã‚°ã‚’ä¿å­˜
    """
    try:
        # ãƒ•ã‚©ãƒ«ãƒ€ä½œæˆ
        os.makedirs(folder_path, exist_ok=True)
        
        log_file = os.path.join(folder_path, "_execution_log.json")
        
        # æ—¢å­˜ãƒ­ã‚°èª­ã¿è¾¼ã¿
        logs = []
        if os.path.exists(log_file):
            try:
                with open(log_file, 'r', encoding='utf-8') as f:
                    logs = json.load(f)
            except json.JSONDecodeError:
                logs = []  # ç ´æãƒ•ã‚¡ã‚¤ãƒ«ã¯åˆæœŸåŒ–
        
        # æ–°è¦ãƒ­ã‚°ã‚’è¿½åŠ 
        logs.append(log_data)
        
        # æœ€æ–°10ä»¶ã®ã¿ä¿æŒ
        logs = logs[-10:]
        
        # ä¿å­˜
        with open(log_file, 'w', encoding='utf-8') as f:
            json.dump(logs, f, ensure_ascii=False, indent=2)
        
        # ã‚µãƒãƒªãƒ¼ãƒ­ã‚°ã‚‚ä¿å­˜
        save_execution_summary(folder_path, log_data)
        
        return {
            "status": "success",
            "message": f"å®Ÿè¡Œãƒ­ã‚°ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {log_file}",
            "log_entry": log_data
        }
    
    except Exception as e:
        return {
            "status": "error",
            "message": f"ãƒ­ã‚°ä¿å­˜ã‚¨ãƒ©ãƒ¼: {str(e)}",
            "error": str(e)
        }

def save_execution_summary(folder_path, log_data):
    """
    å®Ÿè¡Œã‚µãƒãƒªãƒ¼ã®ä¿å­˜ï¼ˆæœ€æ–°å®Ÿè¡Œã®æ¦‚è¦ï¼‰
    """
    summary_file = os.path.join(folder_path, "_latest_execution.json")
    
    summary = {
        "execution_id": log_data["execution_id"],
        "timestamp": log_data["start_time"],
        "research_type": log_data["research_type"],
        "target": log_data["target"],
        "status": log_data["status"],
        "duration_sec": log_data["duration"],
        "quality_score": log_data["quality_score"],
        "source_count": log_data["sources"],
        "cost_jpy": round(log_data["cost"], 2),
        "has_errors": len(log_data["errors"]) > 0,
        "has_warnings": len(log_data["warnings"]) > 0,
        "output_files": [f["path"] for f in log_data["files"]]
    }
    
    try:
        with open(summary_file, 'w', encoding='utf-8') as f:
            json.dump(summary, f, ensure_ascii=False, indent=2)
    except Exception:
        pass  # ã‚µãƒãƒªãƒ¼ä¿å­˜å¤±æ•—ã¯ç„¡è¦–

def get_execution_statistics(folder_path):
    """
    å®Ÿè¡Œçµ±è¨ˆã®å–å¾—
    """
    log_file = os.path.join(folder_path, "_execution_log.json")
    
    if not os.path.exists(log_file):
        return {
            "total_executions": 0,
            "success_rate": 0,
            "avg_duration": 0,
            "avg_quality_score": 0,
            "total_cost": 0
        }
    
    try:
        with open(log_file, 'r', encoding='utf-8') as f:
            logs = json.load(f)
        
        if not logs:
            return {"total_executions": 0}
        
        # çµ±è¨ˆè¨ˆç®—
        total = len(logs)
        successful = len([l for l in logs if l["status"] == "completed"])
        
        return {
            "total_executions": total,
            "success_rate": successful / total if total > 0 else 0,
            "avg_duration": sum(l["duration"] for l in logs) / total,
            "avg_quality_score": sum(l["quality_score"] for l in logs) / total,
            "total_cost": sum(l["cost"] for l in logs),
            "avg_sources": sum(l["sources"] for l in logs) / total,
            "error_rate": len([l for l in logs if len(l["errors"]) > 0]) / total
        }
    
    except Exception:
        return {"total_executions": 0, "error": "çµ±è¨ˆå–å¾—å¤±æ•—"}
```

## ä½¿ç”¨æ–¹æ³•

### 1. èª¿æŸ»é–‹å§‹æ™‚
```python
# èª¿æŸ»é–‹å§‹
log_data = init_execution_log("market_research", "é›»å‹•æ­¯ãƒ–ãƒ©ã‚·å¸‚å ´", "claude")
```

### 2. æ¤œç´¢å®Ÿè¡Œæ™‚
```python
# æ¤œç´¢å®Ÿè¡Œå¾Œ
log_data = log_search_call(log_data, "é›»å‹•æ­¯ãƒ–ãƒ©ã‚· å¸‚å ´è¦æ¨¡", results_count=5, tokens_used=1500)
```

### 3. ä¿¡é ¼åº¦è©•ä¾¡æ™‚
```python
# å„ã‚½ãƒ¼ã‚¹ã®ä¿¡é ¼åº¦è©•ä¾¡å¾Œ
log_data = log_credibility_source(log_data, "A")  # Aç´šã‚½ãƒ¼ã‚¹
```

### 4. ã‚¨ãƒ©ãƒ¼ãƒ»è­¦å‘Šç™ºç”Ÿæ™‚
```python
# ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿæ™‚
log_data = log_error(log_data, "æ¤œç´¢APIã‚¨ãƒ©ãƒ¼", "api_error")

# è­¦å‘Šç™ºç”Ÿæ™‚
log_data = log_warning(log_data, "å¤ã„æƒ…å ±æºãŒå«ã¾ã‚Œã¦ã„ã¾ã™", "data_quality")
```

### 5. ãƒ•ã‚¡ã‚¤ãƒ«å‡ºåŠ›æ™‚
```python
# ãƒ•ã‚¡ã‚¤ãƒ«å‡ºåŠ›å¾Œ
log_data = log_output_file(log_data, "Flow/20250127/market_research.md", "markdown")
```

### 6. èª¿æŸ»å®Œäº†æ™‚
```python
# èª¿æŸ»å®Œäº†
log_data = finish_execution_log(log_data, content_length=3500)
result = save_execution_log("Flow/20250127/", log_data)
```

## å®Ÿè¡Œå ±å‘Šã¸ã®è¿½åŠ æƒ…å ±

å„èª¿æŸ»å®Œäº†æ™‚ã®å ±å‘Šã«ä»¥ä¸‹ã®æƒ…å ±ã‚’è¿½åŠ ï¼š

```
ğŸ“Š å®Ÿè¡Œçµ±è¨ˆ:
- å®Ÿè¡ŒID: 20250127_143025
- æ‰€è¦æ™‚é–“: 245ç§’
- æ¤œç´¢å›æ•°: 5å›
- æƒ…å ±æºæ•°: 12ä»¶
- å“è³ªã‚¹ã‚³ã‚¢: 85/100
- æ¨å®šã‚³ã‚¹ãƒˆ: Â¥15.30

ğŸ† å“è³ªè©•ä¾¡:
- Aç´šã‚½ãƒ¼ã‚¹: 4ä»¶ (33%)
- Bç´šã‚½ãƒ¼ã‚¹: 6ä»¶ (50%)
- Cç´šã‚½ãƒ¼ã‚¹: 2ä»¶ (17%)
- ã‚¨ãƒ©ãƒ¼: 0ä»¶
- è­¦å‘Š: 1ä»¶ï¼ˆå¤ã„ãƒ‡ãƒ¼ã‚¿ã‚ã‚Šï¼‰

ğŸ’¾ å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«:
- market_research.md (3.2KB)
- market_research.json (1.8KB)
- _execution_log.json (æ›´æ–°)
```

## ãƒ­ã‚°åˆ†æãƒ»ç›£æŸ»æ©Ÿèƒ½

### 1. å®Ÿè¡Œçµ±è¨ˆã®ç¢ºèª
```python
stats = get_execution_statistics("Stock/talklabel/market-research/")
print(f"æˆåŠŸç‡: {stats['success_rate']:.1%}")
print(f"å¹³å‡å“è³ªã‚¹ã‚³ã‚¢: {stats['avg_quality_score']:.1f}")
print(f"ç´¯è¨ˆã‚³ã‚¹ãƒˆ: Â¥{stats['total_cost']:.2f}")
```

### 2. å“è³ªå‚¾å‘ã®ç›£è¦–
- å“è³ªã‚¹ã‚³ã‚¢60æœªæº€ã®å ´åˆã¯è‡ªå‹•è­¦å‘Š
- ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿç‡ãŒ20%ã‚’è¶…ãˆã‚‹å ´åˆã¯ã‚¢ãƒ©ãƒ¼ãƒˆ
- ã‚³ã‚¹ãƒˆè¶…éæ™‚ã®è‡ªå‹•åœæ­¢

## è¨­å®š

config/research_config.yamlã«ä»¥ä¸‹ã‚’è¿½åŠ ï¼š
```yaml
logging:
  enabled: true
  max_log_entries: 10
  include_traceback: true
  auto_cleanup_old_logs: true
  quality_threshold: 60
  cost_alert_threshold: 500  # å††
```