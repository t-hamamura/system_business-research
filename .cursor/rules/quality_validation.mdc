# ãƒ¬ãƒãƒ¼ãƒˆå“è³ªè‡ªå‹•æ¤œè¨¼æ©Ÿèƒ½ãƒ«ãƒ¼ãƒ«ï¼ˆv2.0: åŒ…æ‹¬çš„å“è³ªç®¡ç†ï¼‰

## æ¦‚è¦
ç”Ÿæˆã•ã‚ŒãŸãƒ¬ãƒãƒ¼ãƒˆã®å“è³ªã‚’è‡ªå‹•æ¤œè¨¼ã—ã€ä¸è¶³é …ç›®ã®æ¤œå‡ºã€æ”¹å–„ææ¡ˆã€å“è³ªã‚¹ã‚³ã‚¢ã®ç®—å‡ºã‚’è¡Œã†ã€‚

## å“è³ªæ¤œè¨¼æ©Ÿèƒ½
```python
import re
import json
import os
from datetime import datetime

def validate_report_quality(content, report_type, metadata=None):
    """
    ãƒ¬ãƒãƒ¼ãƒˆå“è³ªã‚’åŒ…æ‹¬çš„ã«æ¤œè¨¼
    """
    validation_results = {
        "passed": True,
        "score": 100,
        "grade": "A",
        "issues": [],
        "warnings": [],
        "suggestions": [],
        "metrics": {},
        "timestamp": datetime.now().isoformat()
    }
    
    # 1. åŸºæœ¬æ§‹é€ ãƒã‚§ãƒƒã‚¯
    validation_results = check_basic_structure(content, report_type, validation_results)
    
    # 2. ã‚³ãƒ³ãƒ†ãƒ³ãƒ„å“è³ªãƒã‚§ãƒƒã‚¯
    validation_results = check_content_quality(content, validation_results)
    
    # 3. ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹å“è³ªãƒã‚§ãƒƒã‚¯
    validation_results = check_evidence_quality(content, validation_results)
    
    # 4. ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆå®Œæˆåº¦ãƒã‚§ãƒƒã‚¯
    validation_results = check_template_completion(content, validation_results)
    
    # 5. å®Ÿè¡Œãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒã‚§ãƒƒã‚¯
    if metadata:
        validation_results = check_execution_metadata(metadata, validation_results)
    
    # 6. æœ€çµ‚ã‚¹ã‚³ã‚¢è¨ˆç®—ã¨ã‚°ãƒ¬ãƒ¼ãƒ‰åˆ¤å®š
    validation_results = calculate_final_grade(validation_results)
    
    return validation_results

def check_basic_structure(content, report_type, results):
    """
    åŸºæœ¬æ§‹é€ ã®æ¤œè¨¼
    """
    # å¿…é ˆã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®å®šç¾©
    required_sections = {
        "market_research": [
            "ã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–ã‚µãƒãƒªãƒ¼", "ä¸»è¦ãƒ•ã‚¡ã‚¤ãƒ³ãƒ‡ã‚£ãƒ³ã‚°", "å¸‚å ´æ¦‚æ³", 
            "æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³", "ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹ä¸€è¦§"
        ],
        "competitor_analysis": [
            "ã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–ã‚µãƒãƒªãƒ¼", "ä¸»è¦ãƒ•ã‚¡ã‚¤ãƒ³ãƒ‡ã‚£ãƒ³ã‚°", "ç«¶åˆç’°å¢ƒæ¦‚æ³", 
            "ä¸»è¦ç«¶åˆåˆ†æ", "æ¨å¥¨æˆ¦ç•¥", "ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹ä¸€è¦§"
        ],
        "user_voice_analysis": [
            "ã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–ã‚µãƒãƒªãƒ¼", "ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆåˆ†æ", "ä¸»è¦ãªè©•ä¾¡ãƒã‚¤ãƒ³ãƒˆ", 
            "æ”¹å–„ææ¡ˆ", "ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹ä¸€è¦§"
        ],
        "trend_analysis": [
            "ã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–ã‚µãƒãƒªãƒ¼", "ä¸»è¦ãƒˆãƒ¬ãƒ³ãƒ‰", "å½±éŸ¿åˆ†æ", 
            "å°†æ¥äºˆæ¸¬", "æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³", "ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹ä¸€è¦§"
        ],
        "partner_research": [
            "ã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–ã‚µãƒãƒªãƒ¼", "ãƒ‘ãƒ¼ãƒˆãƒŠãƒ¼å€™è£œåˆ†æ", "è©•ä¾¡ã‚µãƒãƒªãƒ¼", 
            "æ¨å¥¨ãƒ‘ãƒ¼ãƒˆãƒŠãƒ¼", "ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹ä¸€è¦§"
        ]
    }
    
    sections = required_sections.get(report_type, [])
    
    for section in sections:
        if section not in content:
            results["issues"].append(f"å¿…é ˆã‚»ã‚¯ã‚·ãƒ§ãƒ³ã€Œ{section}ã€ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            results["score"] -= 10
            results["passed"] = False
        else:
            # ã‚»ã‚¯ã‚·ãƒ§ãƒ³ãŒç©ºã§ãªã„ã‹ãƒã‚§ãƒƒã‚¯
            section_pattern = f"{section}.*?(?=##|$)"
            section_match = re.search(section_pattern, content, re.DOTALL)
            if section_match:
                section_content = section_match.group(0)
                # ã‚»ã‚¯ã‚·ãƒ§ãƒ³å†…å®¹ãŒçŸ­ã™ãã‚‹å ´åˆ
                if len(section_content.strip()) < 100:
                    results["warnings"].append(f"ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã€Œ{section}ã€ã®å†…å®¹ãŒçŸ­ã™ãã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™")
                    results["score"] -= 3
    
    # åŸºæœ¬ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨˜éŒ²
    results["metrics"]["total_sections"] = len(sections)
    results["metrics"]["found_sections"] = len([s for s in sections if s in content])
    
    return results

def check_content_quality(content, results):
    """
    ã‚³ãƒ³ãƒ†ãƒ³ãƒ„å“è³ªã®æ¤œè¨¼
    """
    # 1. æœ€å°æ–‡å­—æ•°ãƒã‚§ãƒƒã‚¯
    content_length = len(content)
    results["metrics"]["content_length"] = content_length
    
    if content_length < 2000:
        results["issues"].append(f"ãƒ¬ãƒãƒ¼ãƒˆãŒçŸ­ã™ãã¾ã™ï¼ˆ{content_length}æ–‡å­—ï¼‰ã€‚æœ€ä½2000æ–‡å­—å¿…è¦ã§ã™ã€‚")
        results["score"] -= 20
        results["passed"] = False
    elif content_length < 3000:
        results["warnings"].append("ãƒ¬ãƒãƒ¼ãƒˆãŒã‚„ã‚„çŸ­ã‚ã§ã™ã€‚ã‚ˆã‚Šè©³ç´°ãªåˆ†æã‚’æ¨å¥¨ã—ã¾ã™ã€‚")
        results["score"] -= 5
    
    # 2. æœ€å¤§æ–‡å­—æ•°ãƒã‚§ãƒƒã‚¯
    if content_length > 8000:
        results["warnings"].append("ãƒ¬ãƒãƒ¼ãƒˆãŒé•·ã™ãã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚è¦ç‚¹ã‚’æ•´ç†ã™ã‚‹ã“ã¨ã‚’æ¨å¥¨ã—ã¾ã™ã€‚")
        results["score"] -= 3
    
    # 3. æ®µè½æ§‹é€ ãƒã‚§ãƒƒã‚¯
    paragraphs = content.split('\n\n')
    short_paragraphs = [p for p in paragraphs if len(p.strip()) < 50 and p.strip()]
    
    if len(short_paragraphs) > len(paragraphs) * 0.3:
        results["warnings"].append("çŸ­ã„æ®µè½ãŒå¤šã™ãã¾ã™ã€‚å†…å®¹ã‚’ã‚ˆã‚Šè©³ã—ãè¨˜è¿°ã—ã¦ãã ã•ã„ã€‚")
        results["score"] -= 5
    
    # 4. æ•°å€¤ãƒ‡ãƒ¼ã‚¿ã®å­˜åœ¨ãƒã‚§ãƒƒã‚¯
    number_pattern = r'\d+[.,]?\d*[%ä¸‡å††å…†åƒç™¾å„„]'
    numbers = re.findall(number_pattern, content)
    results["metrics"]["numeric_data_count"] = len(numbers)
    
    if len(numbers) < 3:
        results["warnings"].append("å…·ä½“çš„ãªæ•°å€¤ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚å®šé‡çš„ãªæƒ…å ±ã‚’è¿½åŠ ã—ã¦ãã ã•ã„ã€‚")
        results["score"] -= 8
    
    # 5. å°‚é–€ç”¨èªãƒ»æ¥­ç•Œç”¨èªã®é©åˆ‡æ€§
    jargon_patterns = [
        r'[A-Z]{2,5}',  # ç•¥èª
        r'(?:ãƒãƒ¼ã‚±ãƒƒãƒˆ|ãƒ‹ãƒ¼ã‚º|ã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³|ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ )',  # ãƒ“ã‚¸ãƒã‚¹ç”¨èª
    ]
    
    jargon_count = 0
    for pattern in jargon_patterns:
        jargon_count += len(re.findall(pattern, content))
    
    results["metrics"]["business_terms_count"] = jargon_count
    
    return results

def check_evidence_quality(content, results):
    """
    ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹å“è³ªã®æ¤œè¨¼
    """
    # 1. ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹ãƒ†ãƒ¼ãƒ–ãƒ«ã®å­˜åœ¨ãƒã‚§ãƒƒã‚¯
    if "ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹ä¸€è¦§" not in content:
        results["issues"].append("ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹ä¸€è¦§ã‚»ã‚¯ã‚·ãƒ§ãƒ³ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        results["score"] -= 15
        results["passed"] = False
        return results
    
    # 2. ãƒ†ãƒ¼ãƒ–ãƒ«è¡Œæ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
    table_rows = content.count("\n|") - content.count("\n|---|")  # ãƒ˜ãƒƒãƒ€ãƒ¼åŒºåˆ‡ã‚Šç·šé™¤å¤–
    results["metrics"]["evidence_table_rows"] = table_rows
    
    if table_rows < 5:  # æœ€ä½5ã‚½ãƒ¼ã‚¹
        results["issues"].append(f"ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹ãƒ†ãƒ¼ãƒ–ãƒ«ã®ã‚½ãƒ¼ã‚¹æ•°ãŒä¸è¶³ã—ã¦ã„ã¾ã™ï¼ˆ{table_rows}ä»¶ï¼‰ã€‚æœ€ä½5ä»¶å¿…è¦ã§ã™ã€‚")
        results["score"] -= 15
        results["passed"] = False
    elif table_rows < 8:
        results["warnings"].append("ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹ã‚½ãƒ¼ã‚¹æ•°ãŒã‚„ã‚„å°‘ãªã‚ã§ã™ã€‚ã‚ˆã‚Šå¤šãã®æƒ…å ±æºã‚’æ¨å¥¨ã—ã¾ã™ã€‚")
        results["score"] -= 5
    
    # 3. URLå½¢å¼ãƒã‚§ãƒƒã‚¯
    url_pattern = r'https?://[^\s\|)]+(?:\.[^\s\|)]+)+'
    urls = re.findall(url_pattern, content)
    results["metrics"]["url_count"] = len(urls)
    
    if len(urls) < table_rows * 0.8:  # 80%ä»¥ä¸Šã®ã‚½ãƒ¼ã‚¹ã«URLãŒå¿…è¦
        results["warnings"].append("æœ‰åŠ¹ãªURLãŒä¸è¶³ã—ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™")
        results["score"] -= 8
    
    # 4. ä¿¡é ¼åº¦ãƒ†ã‚£ã‚¢ã®åˆ†å¸ƒãƒã‚§ãƒƒã‚¯
    tier_a = content.count("|A|") + content.count("| A |")
    tier_b = content.count("|B|") + content.count("| B |")
    tier_c = content.count("|C|") + content.count("| C |")
    
    results["metrics"]["credibility_tiers"] = {"A": tier_a, "B": tier_b, "C": tier_c}
    
    total_tiers = tier_a + tier_b + tier_c
    if total_tiers > 0:
        a_ratio = tier_a / total_tiers
        if a_ratio < 0.2:  # Aç´šã‚½ãƒ¼ã‚¹ãŒ20%æœªæº€
            results["warnings"].append("é«˜ä¿¡é ¼åº¦ï¼ˆAç´šï¼‰ã‚½ãƒ¼ã‚¹ã®å‰²åˆãŒä½ã™ãã¾ã™")
            results["score"] -= 10
        elif a_ratio > 0.8:  # Aç´šã‚½ãƒ¼ã‚¹ãŒ80%è¶…
            results["warnings"].append("ä¿¡é ¼åº¦åˆ†å¸ƒãŒåã£ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™")
            results["score"] -= 3
    
    # 5. å¼•ç”¨æŠœç²‹ã®å“è³ªãƒã‚§ãƒƒã‚¯
    quote_pattern = r'\|[^|]{10,200}\|'  # 10-200æ–‡å­—ã®å¼•ç”¨
    quotes = re.findall(quote_pattern, content)
    results["metrics"]["quote_count"] = len(quotes)
    
    if len(quotes) < table_rows * 0.5:
        results["warnings"].append("å¼•ç”¨æŠœç²‹ãŒä¸è¶³ã—ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™")
        results["score"] -= 5
    
    return results

def check_template_completion(content, results):
    """
    ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆå®Œæˆåº¦ãƒã‚§ãƒƒã‚¯
    """
    # 1. æœªç½®æ›ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆå¤‰æ•°ãƒã‚§ãƒƒã‚¯
    placeholder_patterns = [
        r'\{\{[^}]+\}\}',  # {{variable}}
        r'\[.*?\]',        # [placeholder]
        r'TODO',           # TODO markers
        r'N/A',            # Not Available
        r'åˆ†æä¸­',          # åˆ†æä¸­
        r'èª¿æŸ»ä¸­',          # èª¿æŸ»ä¸­
        r'è¦ç¢ºèª',          # è¦ç¢ºèª
        r'æœªå®š',           # æœªå®š
    ]
    
    placeholders_found = []
    for pattern in placeholder_patterns:
        matches = re.findall(pattern, content)
        placeholders_found.extend(matches)
    
    results["metrics"]["placeholders_found"] = len(placeholders_found)
    
    if placeholders_found:
        results["issues"].append(f"æœªå®Œæˆã®ç®‡æ‰€ãŒã‚ã‚Šã¾ã™: {placeholders_found[:3]}")
        results["score"] -= 15
        results["passed"] = False
    
    # 2. ç©ºã‚»ã‚¯ã‚·ãƒ§ãƒ³ãƒã‚§ãƒƒã‚¯
    empty_patterns = [
        r'##[^#\n]*\n\s*\n##',      # ç©ºã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆæ¬¡ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã¾ã§ï¼‰
        r'##[^#\n]*\n\s*$',         # æ–‡æœ«ã®ç©ºã‚»ã‚¯ã‚·ãƒ§ãƒ³
        r'ï¼š\s*\n\s*\n',            # ã‚³ãƒ­ãƒ³ã®å¾ŒãŒç©º
        r'ã€‚\s*\n\s*\n##',          # çŸ­ã„èª¬æ˜ã®ã¿ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³
    ]
    
    empty_sections = 0
    for pattern in empty_patterns:
        empty_sections += len(re.findall(pattern, content, re.MULTILINE))
    
    results["metrics"]["empty_sections"] = empty_sections
    
    if empty_sections > 0:
        results["warnings"].append(f"ç©ºã¾ãŸã¯å†…å®¹ã®è–„ã„ã‚»ã‚¯ã‚·ãƒ§ãƒ³ãŒ{empty_sections}ä»¶è¦‹ã¤ã‹ã‚Šã¾ã—ãŸ")
        results["score"] -= empty_sections * 3
    
    return results

def check_execution_metadata(metadata, results):
    """
    å®Ÿè¡Œãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®æ¤œè¨¼
    """
    if not metadata:
        return results
    
    # 1. å®Ÿè¡Œæ™‚é–“ãƒã‚§ãƒƒã‚¯
    duration = metadata.get("duration_sec", 0)
    results["metrics"]["execution_duration"] = duration
    
    if duration < 60:
        results["warnings"].append("å®Ÿè¡Œæ™‚é–“ãŒçŸ­ã™ãã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ååˆ†ãªèª¿æŸ»ãŒè¡Œã‚ã‚Œã¦ã„ãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
        results["score"] -= 10
    elif duration > 600:  # 10åˆ†è¶…
        results["warnings"].append("å®Ÿè¡Œæ™‚é–“ãŒé•·ã™ãã¾ã™ã€‚åŠ¹ç‡æ€§ã‚’æ”¹å–„ã™ã‚‹ä½™åœ°ãŒã‚ã‚Šã¾ã™ã€‚")
        results["score"] -= 3
    
    # 2. æ¤œç´¢å›æ•°ãƒã‚§ãƒƒã‚¯
    search_count = metadata.get("search_count", 0)
    results["metrics"]["search_calls"] = search_count
    
    if search_count < 3:
        results["warnings"].append("æ¤œç´¢å›æ•°ãŒå°‘ãªã™ãã¾ã™ã€‚ã‚ˆã‚Šå¤šè§’çš„ãªæƒ…å ±åé›†ã‚’æ¨å¥¨ã—ã¾ã™ã€‚")
        results["score"] -= 8
    
    # 3. ã‚½ãƒ¼ã‚¹æ•°ãƒã‚§ãƒƒã‚¯
    source_count = metadata.get("source_count", 0)
    if source_count < 5:
        results["issues"].append("æƒ…å ±æºæ•°ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚æœ€ä½5ä»¶å¿…è¦ã§ã™ã€‚")
        results["score"] -= 12
        results["passed"] = False
    
    # 4. ã‚¨ãƒ©ãƒ¼ãƒ»è­¦å‘Šãƒã‚§ãƒƒã‚¯
    error_count = len(metadata.get("errors", []))
    warning_count = len(metadata.get("warnings", []))
    
    if error_count > 0:
        results["warnings"].append(f"å®Ÿè¡Œä¸­ã«{error_count}ä»¶ã®ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ")
        results["score"] -= error_count * 8
    
    if warning_count > 2:
        results["warnings"].append(f"å®Ÿè¡Œä¸­ã«{warning_count}ä»¶ã®è­¦å‘ŠãŒç™ºç”Ÿã—ã¾ã—ãŸ")
        results["score"] -= warning_count * 2
    
    return results

def calculate_final_grade(results):
    """
    æœ€çµ‚ã‚°ãƒ¬ãƒ¼ãƒ‰è¨ˆç®—
    """
    score = max(0, results["score"])
    
    # ã‚°ãƒ¬ãƒ¼ãƒ‰åˆ¤å®š
    if score >= 90:
        grade = "A"
        grade_description = "å„ªç§€"
    elif score >= 80:
        grade = "B"
        grade_description = "è‰¯å¥½"
    elif score >= 70:
        grade = "C"
        grade_description = "æ¨™æº–"
    elif score >= 60:
        grade = "D"
        grade_description = "è¦æ”¹å–„"
    else:
        grade = "F"
        grade_description = "ä¸åˆæ ¼"
        results["passed"] = False
    
    results["score"] = score
    results["grade"] = grade
    results["grade_description"] = grade_description
    
    # æ”¹å–„ææ¡ˆç”Ÿæˆ
    results["suggestions"] = generate_improvement_suggestions(results)
    
    return results

def generate_improvement_suggestions(results):
    """
    æ”¹å–„ææ¡ˆã‚’ç”Ÿæˆ
    """
    suggestions = []
    
    # æ§‹é€ çš„å•é¡Œã®ææ¡ˆ
    if any("å¿…é ˆã‚»ã‚¯ã‚·ãƒ§ãƒ³" in issue for issue in results["issues"]):
        suggestions.append("ä¸è¶³ã—ã¦ã„ã‚‹å¿…é ˆã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’è¿½åŠ ã—ã¦ãã ã•ã„ã€‚ç‰¹ã«ã€Œã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹ä¸€è¦§ã€ã¯å“è³ªå‘ä¸Šã«é‡è¦ã§ã™ã€‚")
    
    # ã‚³ãƒ³ãƒ†ãƒ³ãƒ„é‡ã®ææ¡ˆ
    content_length = results["metrics"].get("content_length", 0)
    if content_length < 2000:
        suggestions.append("ã‚ˆã‚Šè©³ç´°ãªåˆ†æã‚’è¿½åŠ ã—ã¦ãã ã•ã„ã€‚ç‰¹ã«ã€Œå¸‚å ´å‹•å‘ã€ã€Œç«¶åˆæ¯”è¼ƒã€ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’å……å®Ÿã•ã›ã‚‹ã“ã¨ã‚’æ¨å¥¨ã—ã¾ã™ã€‚")
    
    # ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹ã®ææ¡ˆ
    evidence_rows = results["metrics"].get("evidence_table_rows", 0)
    if evidence_rows < 5:
        suggestions.append("web_searchã‚’å†å®Ÿè¡Œã—ã¦ã‚ˆã‚Šå¤šãã®æƒ…å ±æºã‚’å–å¾—ã—ã€ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’å……å®Ÿã•ã›ã¦ãã ã•ã„ã€‚")
    
    # æ•°å€¤ãƒ‡ãƒ¼ã‚¿ã®ææ¡ˆ
    numeric_count = results["metrics"].get("numeric_data_count", 0)
    if numeric_count < 3:
        suggestions.append("å¸‚å ´è¦æ¨¡ã€æˆé•·ç‡ã€ã‚·ã‚§ã‚¢ãªã©ã®å…·ä½“çš„ãªæ•°å€¤ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ ã—ã¦ãã ã•ã„ã€‚")
    
    # ä¿¡é ¼åº¦åˆ†å¸ƒã®ææ¡ˆ
    tiers = results["metrics"].get("credibility_tiers", {})
    total_tiers = sum(tiers.values())
    if total_tiers > 0 and tiers.get("A", 0) / total_tiers < 0.2:
        suggestions.append("ã‚ˆã‚Šä¿¡é ¼åº¦ã®é«˜ã„æƒ…å ±æºï¼ˆæ”¿åºœçµ±è¨ˆã€æ¥­ç•Œãƒ¬ãƒãƒ¼ãƒˆã€ä¸Šå ´ä¼æ¥­IRç­‰ï¼‰ã‚’è¿½åŠ ã—ã¦ãã ã•ã„ã€‚")
    
    # æœªå®Œæˆç®‡æ‰€ã®ææ¡ˆ
    if results["metrics"].get("placeholders_found", 0) > 0:
        suggestions.append("æœªç½®æ›ã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆå¤‰æ•°ã‚„TODOãƒãƒ¼ã‚«ãƒ¼ã‚’è§£æ±ºã—ã¦ãã ã•ã„ã€‚å¿…è¦ã«å¿œã˜ã¦è¿½åŠ æ¤œç´¢ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
    
    return suggestions

def save_validation_report(folder_path, validation_results, original_content):
    """
    æ¤œè¨¼ãƒ¬ãƒãƒ¼ãƒˆã®ä¿å­˜
    """
    try:
        os.makedirs(folder_path, exist_ok=True)
        
        # æ¤œè¨¼çµæœã‚’JSONã§ä¿å­˜
        validation_file = os.path.join(folder_path, "_quality_validation.json")
        with open(validation_file, 'w', encoding='utf-8') as f:
            json.dump(validation_results, f, ensure_ascii=False, indent=2)
        
        # äººé–“å¯èª­ãªãƒ¬ãƒãƒ¼ãƒˆã‚‚ç”Ÿæˆ
        readable_report = generate_readable_validation_report(validation_results)
        report_file = os.path.join(folder_path, "_quality_report.md")
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(readable_report)
        
        return {
            "status": "success",
            "validation_file": validation_file,
            "report_file": report_file
        }
    
    except Exception as e:
        return {
            "status": "error",
            "message": f"æ¤œè¨¼ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜ã‚¨ãƒ©ãƒ¼: {str(e)}"
        }

def generate_readable_validation_report(results):
    """
    äººé–“å¯èª­ãªæ¤œè¨¼ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    """
    report = f"""# ãƒ¬ãƒãƒ¼ãƒˆå“è³ªæ¤œè¨¼çµæœ

## ç·åˆè©•ä¾¡
- **ã‚°ãƒ¬ãƒ¼ãƒ‰**: {results['grade']} ({results['grade_description']})
- **ã‚¹ã‚³ã‚¢**: {results['score']}/100
- **åˆæ ¼åˆ¤å®š**: {'âœ… åˆæ ¼' if results['passed'] else 'âŒ ä¸åˆæ ¼'}
- **æ¤œè¨¼æ—¥æ™‚**: {results['timestamp']}

## å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹
"""
    
    for key, value in results['metrics'].items():
        report += f"- {key}: {value}\n"
    
    if results['issues']:
        report += "\n## âŒ é‡è¦ãªå•é¡Œ\n"
        for issue in results['issues']:
            report += f"- {issue}\n"
    
    if results['warnings']:
        report += "\n## âš ï¸ è­¦å‘Šãƒ»æ”¹å–„ç‚¹\n"
        for warning in results['warnings']:
            report += f"- {warning}\n"
    
    if results['suggestions']:
        report += "\n## ğŸ’¡ æ”¹å–„ææ¡ˆ\n"
        for suggestion in results['suggestions']:
            report += f"- {suggestion}\n"
    
    report += f"""
## å“è³ªåŸºæº–
- **A (90-100)**: å„ªç§€ - å•†ç”¨ãƒ¬ãƒ™ãƒ«ã®é«˜å“è³ªãƒ¬ãƒãƒ¼ãƒˆ
- **B (80-89)**: è‰¯å¥½ - è»½å¾®ãªæ”¹å–„ã§å•†ç”¨åˆ©ç”¨å¯èƒ½  
- **C (70-79)**: æ¨™æº– - åŸºæœ¬è¦ä»¶ã¯æº€ãŸã—ã¦ã„ã‚‹ãŒæ”¹å–„ä½™åœ°ã‚ã‚Š
- **D (60-69)**: è¦æ”¹å–„ - å¤§å¹…ãªä¿®æ­£ãŒå¿…è¦
- **F (0-59)**: ä¸åˆæ ¼ - å†ä½œæˆã‚’æ¨å¥¨
"""
    
    return report
```

## ä½¿ç”¨æ–¹æ³•

### 1. ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆç›´å¾Œã®è‡ªå‹•æ¤œè¨¼
```python
# ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆå®Œäº†å¾Œ
validation_results = validate_report_quality(
    content=report_content,
    report_type="market_research", 
    metadata=execution_log_data
)

# çµæœã‚’è¡¨ç¤º
print(f"å“è³ªã‚¹ã‚³ã‚¢: {validation_results['score']}/100 (ã‚°ãƒ¬ãƒ¼ãƒ‰: {validation_results['grade']})")

if not validation_results['passed']:
    print("âŒ å“è³ªåŸºæº–ã‚’æº€ãŸã—ã¦ã„ã¾ã›ã‚“ã€‚ä»¥ä¸‹ã®å•é¡Œã‚’ä¿®æ­£ã—ã¦ãã ã•ã„ï¼š")
    for issue in validation_results['issues']:
        print(f"  - {issue}")
```

### 2. æ¤œè¨¼ãƒ¬ãƒãƒ¼ãƒˆã®ä¿å­˜
```python
# æ¤œè¨¼çµæœã‚’ä¿å­˜
save_result = save_validation_report(
    folder_path="Flow/20250127/market-research/",
    validation_results=validation_results,
    original_content=report_content
)
```

### 3. å“è³ªæ”¹å–„ã®è‡ªå‹•ææ¡ˆ
```python
# æ”¹å–„ææ¡ˆã®è¡¨ç¤º
if validation_results['suggestions']:
    print("ğŸ’¡ å“è³ªå‘ä¸Šã®ãŸã‚ã®ææ¡ˆ:")
    for suggestion in validation_results['suggestions']:
        print(f"  - {suggestion}")
```

## å“è³ªã‚¹ã‚³ã‚¢è©³ç´°

### ã‚¹ã‚³ã‚¢æ§‹æˆ
- **åŸºæœ¬æ§‹é€  (40ç‚¹)**: å¿…é ˆã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®å®Œå‚™
- **ã‚³ãƒ³ãƒ†ãƒ³ãƒ„å“è³ª (25ç‚¹)**: æ–‡å­—æ•°ã€æ®µè½æ§‹é€ ã€æ•°å€¤ãƒ‡ãƒ¼ã‚¿
- **ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹å“è³ª (25ç‚¹)**: ã‚½ãƒ¼ã‚¹æ•°ã€ä¿¡é ¼åº¦ã€å¼•ç”¨å“è³ª
- **å®Œæˆåº¦ (10ç‚¹)**: ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆå®Œæˆã€ç©ºã‚»ã‚¯ã‚·ãƒ§ãƒ³é™¤å»

### æ¸›ç‚¹é …ç›®
- å¿…é ˆã‚»ã‚¯ã‚·ãƒ§ãƒ³ä¸è¶³: -10ç‚¹/ã‚»ã‚¯ã‚·ãƒ§ãƒ³
- æ–‡å­—æ•°ä¸è¶³: -20ç‚¹ï¼ˆ2000æ–‡å­—æœªæº€ï¼‰
- ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹ä¸è¶³: -15ç‚¹ï¼ˆ5ã‚½ãƒ¼ã‚¹æœªæº€ï¼‰
- æœªå®Œæˆç®‡æ‰€: -15ç‚¹
- ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆå¤‰æ•°æ®‹å­˜: -15ç‚¹

## è¨­å®šã‚ªãƒ—ã‚·ãƒ§ãƒ³

config/research_config.yamlã«è¿½åŠ ï¼š
```yaml
quality_validation:
  enabled: true
  auto_validate: true           # è‡ªå‹•æ¤œè¨¼ã®æœ‰åŠ¹åŒ–
  min_passing_score: 60         # åˆæ ¼æœ€ä½ç‚¹
  save_validation_report: true  # æ¤œè¨¼ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜
  strict_mode: false           # å³æ ¼ãƒ¢ãƒ¼ãƒ‰ï¼ˆAã‚°ãƒ¬ãƒ¼ãƒ‰è¦æ±‚ï¼‰
  auto_retry_on_fail: true     # ä¸åˆæ ¼æ™‚ã®è‡ªå‹•å†è©¦è¡Œ
```